{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59575,"databundleVersionId":8060720,"sourceType":"competition"},{"sourceId":8323913,"sourceType":"datasetVersion","datasetId":4944579},{"sourceId":8413600,"sourceType":"datasetVersion","datasetId":5007812},{"sourceId":8479599,"sourceType":"datasetVersion","datasetId":4517815},{"sourceId":8683506,"sourceType":"datasetVersion","datasetId":5205913},{"sourceId":8740576,"sourceType":"datasetVersion","datasetId":5205988},{"sourceId":174185912,"sourceType":"kernelVersion"},{"sourceId":27825,"sourceType":"modelInstanceVersion","modelInstanceId":22009}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\n\nimport keras_nlp\nimport keras\n\nfrom collections import Counter\n\nimport re\nimport whoosh_utils\nimport whoosh\n\nimport os\nimport gc\n\n\npd.set_option('display.max_rows', 200)\npd.options.mode.copy_on_write = True","metadata":{"execution":{"iopub.status.busy":"2024-06-22T18:59:47.276894Z","iopub.execute_input":"2024-06-22T18:59:47.277281Z","iopub.status.idle":"2024-06-22T19:00:36.842641Z","shell.execute_reply.started":"2024-06-22T18:59:47.277244Z","shell.execute_reply":"2024-06-22T19:00:36.841709Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-22 18:59:49.579932: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-22 18:59:49.580042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-22 18:59:49.723073: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\nInstalling collected packages: Whoosh\nSuccessfully installed Whoosh-2.7.4\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    dataset_path = \"/kaggle/input/uspto-explainable-ai\"\n    preset = \"gemma_1.1_instruct_2b_en\" # name of pretrained Gemma\n    input_length = 1024 # max size of input sequence for training\n    output_length = 1200 # max size of output sequence\n    num_neighbors = 3 # how many neighbour patents to consider\n    n_main_cpc = 2","metadata":{"execution":{"iopub.status.busy":"2024-06-22T19:00:36.844524Z","iopub.execute_input":"2024-06-22T19:00:36.845111Z","iopub.status.idle":"2024-06-22T19:00:36.850607Z","shell.execute_reply.started":"2024-06-22T19:00:36.845081Z","shell.execute_reply":"2024-06-22T19:00:36.849459Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#os.chdir('/kaggle/input/uspto-explainable-ai/')\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n\nkeras.utils.set_random_seed(CFG.seed)\n\nprint(\"Keras:\", keras.__version__)\nprint(\"KerasNLP:\", keras_nlp.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T19:00:36.852077Z","iopub.execute_input":"2024-06-22T19:00:36.852411Z","iopub.status.idle":"2024-06-22T19:00:36.878333Z","shell.execute_reply.started":"2024-06-22T19:00:36.852384Z","shell.execute_reply":"2024-06-22T19:00:36.877325Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Keras: 3.3.3\nKerasNLP: 0.12.1\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# test_df, где 2 соседа входят в индекс\n\n'''\n%%time\nindex_list = pd.read_json('/kaggle/input/uspto-explainable-ai/train_index_patent_ids.json')\n\nnn_columns = pd.read_csv('/kaggle/input/uspto-explainable-ai/nearest_neighbors.csv', header=0, nrows = 1).columns\n\ntest_df = pd.read_csv('/kaggle/input/uspto-explainable-ai/nearest_neighbors.csv', names=nn_columns, skiprows=0, nrows = 1000000)\ntest_df = test_df[(test_df.neighbor_0.isin(index_list[0])) \n               & (test_df.neighbor_1.isin(index_list[0]))]\n\nfor i in range(1, 14):\n    test_df1 = pd.read_csv('/kaggle/input/uspto-explainable-ai/nearest_neighbors.csv', names=nn_columns, skiprows=i * 1000000, nrows = 1000000)\n\n    test_df = pd.concat([test_df, \n                         test_df1[(test_df1.neighbor_0.isin(index_list[0])) \n                                  & (test_df1.neighbor_1.isin(index_list[0]))\n                                 ]\n                        ])\n    print(i, test_df.shape, test_df1.shape)\n    \n    \ntest_df.to_pickle('/kaggle/working/test_df.pkl')\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df для работы n - кол-во \"соседей\" в индексе\n# + main_cpc_codes\n'''\n%%time\ntest_df = pd.read_pickle('/kaggle/input/test-df/test_df.pkl')\n#test_df = pd.read_pickle('/kaggle/working/test_df.pkl')\nprint(test_df.shape)\n\nindex_list = pd.read_json('/kaggle/input/uspto-explainable-ai/train_index_patent_ids.json')\n\ntest_df['nn'] = 0\n\nfor i in range(50):\n    test_df.loc[test_df['neighbor_'+str(i)].isin(index_list[0].values), 'nn'] = test_df['nn'] + 1\n    \ntest_df = test_df[test_df.nn>2]\n\nmeta_df = pd.read_parquet(f\"{CFG.dataset_path}/patent_metadata.parquet\")\n\nmain_cpc_codes = []\nfor _, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n    df = meta_df[meta_df.publication_number.isin(row[:51].values)]\n    cpc = df.cpc_codes.values\n    \n    counter_object = Counter([x for sub_list in cpc for x in sub_list])\n    key_cpc = [x[0] for x in counter_object.most_common()][:CFG.n_main_cpc]\n    df['cc'] = 0\n    \n    for code in key_cpc:\n        df.loc[df['cpc_codes'].apply(lambda x: key_cpc[1] in x), 'cc'] = df['cc'] + 1\n        \n    df1 = df[df['cc']==0]\n    while df1.shape[0] > 0:\n        cpc = df1.cpc_codes.values\n        counter_object = Counter([x for sub_list in cpc for x in sub_list])\n        \n        try:\n            add_cpc = counter_object.most_common()[0][0]\n            df1.loc[df1['cpc_codes'].apply(lambda x: add_cpc in x), 'cc'] = df1['cc'] + 1\n            key_cpc.append(add_cpc)\n            df1 = df1[df1['cc']==0]\n        except:\n            break\n        \n    main_cpc_codes.append(key_cpc)\n\ntest_df[\"main_cpc\"] = main_cpc_codes\n\ndel meta_df\ngc.collect()\n\nprint(test_df.shape, test_df.columns)\n'''","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 2846/2846 [35:52<00:00,  1.32it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n#uncomment before submit\n\ntest_df = pd.read_csv(f\"{CFG.dataset_path}/test.csv\")\n#test_df = test_df.iloc[:, :CFG.num_neighbors+1]\ntarget_cols = list(test_df.columns[1:CFG.num_neighbors+1])\n\n# Merge metadata of the patents\nmeta_df = pd.read_parquet(f\"{CFG.dataset_path}/patent_metadata.parquet\")\ntest_df = test_df.merge(meta_df, on=\"publication_number\", how=\"left\")\n\n# Merge Title and Abstract of the patennts\nall_patents = pd.read_parquet(\"/kaggle/input/uspto-all-patents-after-1975/all_patents.parquet\")\ntest_df = test_df.merge(all_patents, on=\"publication_number\")\n\n# Fill NaN values\ntest_df[\"title\"] = test_df[\"title\"].fillna(\"\")\ntest_df[\"abstract\"] = test_df[\"abstract\"].fillna(\"\")\n\n# Merge Title and Abstract of the neighbour patents\nfor i in range(CFG.num_neighbors):\n    test_df = test_df.merge(\n        all_patents,\n        left_on=target_cols[i],\n        right_on=\"publication_number\",\n        how=\"left\",\n        suffixes=(\"\", f\"_{i}\")\n    )\n\n    '''test_df = test_df.merge(\n        meta_df[['publication_number', 'cpc_codes']],\n        left_on=target_cols[i],\n        right_on=\"publication_number\",\n        how=\"left\",\n        suffixes=(\"\", f\"__{i}\")\n    )\n\n    # Fill NaN values\n    test_df[f\"cpc_codes__{i}\"] = test_df[f\"cpc_codes__{i}\"].fillna(\"\")'''\n    \n    test_df[f\"title_{i}\"] = test_df[f\"title_{i}\"].fillna(\"\")\n    test_df[f\"abstract_{i}\"] = test_df[f\"abstract_{i}\"].fillna(\"\")\n\n    # Drop extra publication_number column from merges\n    test_df = test_df.drop(columns=[f\"publication_number_{i}\"])    #, f\"publication_number__{i}\"])\n\nmain_cpc_codes = []\nfor _, row in tqdm(test_df.iterrows()):\n    df = meta_df[meta_df.publication_number.isin(row[:51].values)]\n    cpc = df.cpc_codes.values\n    \n    counter_object = Counter([x for sub_list in cpc for x in sub_list])\n    key_cpc = [x[0] for x in counter_object.most_common()][:CFG.n_main_cpc]\n    df['cc'] = 0\n    \n    for code in key_cpc:\n        df.loc[df['cpc_codes'].apply(lambda x: key_cpc[1] in x), 'cc'] = df['cc'] + 1\n        \n    df1 = df[df['cc']==0]\n    while df1.shape[0] > 0:\n        cpc = df1.cpc_codes.values\n        counter_object = Counter([x for sub_list in cpc for x in sub_list])\n        \n        try:\n            add_cpc = counter_object.most_common()[0][0]\n            df1.loc[df1['cpc_codes'].apply(lambda x: add_cpc in x), 'cc'] = df1['cc'] + 1\n            key_cpc.append(add_cpc)\n            df1 = df1[df1['cc']==0]\n        except:\n            break       \n         \n    main_cpc_codes.append(key_cpc)\n\ntest_df[\"main_cpc\"] = main_cpc_codes\n\ntest_df = test_df.reset_index(drop=True)\n\n# Clean up memory\ndel meta_df, all_patents, df, df1\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:56:38.848715Z","iopub.execute_input":"2024-06-20T17:56:38.849172Z","iopub.status.idle":"2024-06-20T18:00:29.100942Z","shell.execute_reply.started":"2024-06-20T17:56:38.849138Z","shell.execute_reply":"2024-06-20T18:00:29.099869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"%%time\n# Declare the model\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(CFG.preset)\n\n# Set input length of small to keep the memory and latency cost small\ngemma_lm.preprocessor.sequence_length = CFG.input_length","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:11:58.939339Z","iopub.execute_input":"2024-06-22T20:11:58.940309Z","iopub.status.idle":"2024-06-22T20:13:07.114620Z","shell.execute_reply.started":"2024-06-22T20:11:58.940273Z","shell.execute_reply":"2024-06-22T20:13:07.113526Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 11.4 s, sys: 14.1 s, total: 25.5 s\nWall time: 1min 8s\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_prompt(row, neighbor_idx):\n    #prompt = chat_template.format(title_a=row[\"title\"], abstract_a=row[\"abstract\"],\n    #                              title_b=row[f\"title_{neighbor_idx}\"], abstract_b=row[f\"abstract_{neighbor_idx}\"])\n    prompt = chat_template.format(title_a=row[\"title\"], abstract_a=\"\",\n                                  title_b=row[f\"title_{neighbor_idx}\"], abstract_b=\"\")\n    return prompt\n","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:13:07.117010Z","iopub.execute_input":"2024-06-22T20:13:07.117788Z","iopub.status.idle":"2024-06-22T20:13:07.123326Z","shell.execute_reply.started":"2024-06-22T20:13:07.117746Z","shell.execute_reply":"2024-06-22T20:13:07.122311Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def generate_keyword(row, neighbor_idx):\n    # Check if any title or abstract is an empty string\n    fields = [\n        \"title\",\n        #\"abstract\",\n        f\"title_{neighbor_idx}\",\n        #f\"abstract_{neighbor_idx}\",\n    ]\n    if all(row[field] == \"\" for field in fields):\n        return [\"\"]\n\n    # Create prompt\n    prompt = create_prompt(row, neighbor_idx)\n\n    try:\n        output = gemma_lm.generate(prompt, max_length=CFG.output_length).replace(prompt, \"\").strip()\n        \n        for symb in ['**Keywords list:**', 'Keywords list', ':', ';', '$', '?', '.']:\n            output = output.replace(symb, \"\")\n        \n        answer = output.strip().split('\\n* ')\n\n        keywords = [x.replace(\"*\", \"\").strip() for x in set(answer) if len(x) < 50]     \n\n    except:\n        return [\"\"]\n\n    return keywords","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:13:07.124933Z","iopub.execute_input":"2024-06-22T20:13:07.125353Z","iopub.status.idle":"2024-06-22T20:13:07.136834Z","shell.execute_reply.started":"2024-06-22T20:13:07.125314Z","shell.execute_reply":"2024-06-22T20:13:07.135479Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"prompt_template = \"Request:\\nAnalyze and compare the given two patent abstracts and titles, and identify the common and similar keywords that should find specifically these two patents when searched all Patent database.\\n\\nIn the answer provide only the list of keywords, named 'Keywords list:', separating keywords with a '\\n* '. \\n\\nPatent 1:\\n* Title: {title_a}\\n* Abstract: {abstract_a}\\n\\nPatent 2:\\n* Title: {title_b}\\n* Abstract: {abstract_b}\\n\"\n\nchat_template = f\"<start_of_turn>user\\n{prompt_template}<end_of_turn>\\n<start_of_turn>model\\n\"","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-22T20:13:07.139624Z","iopub.execute_input":"2024-06-22T20:13:07.140073Z","iopub.status.idle":"2024-06-22T20:13:07.152389Z","shell.execute_reply.started":"2024-06-22T20:13:07.140034Z","shell.execute_reply":"2024-06-22T20:13:07.151175Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#[print(f\"Keywords {i}: {q}\", end=\"\\n\\n\") for i, q in  enumerate(keywords_all_0[:10])]","metadata":{"execution":{"iopub.status.busy":"2024-06-13T15:46:30.204261Z","iopub.execute_input":"2024-06-13T15:46:30.204635Z","iopub.status.idle":"2024-06-13T15:46:30.214209Z","shell.execute_reply.started":"2024-06-13T15:46:30.204595Z","shell.execute_reply":"2024-06-13T15:46:30.213160Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BRS_STOPWORDS = ['a', 'an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'thus', 'to', 'was', 'will', 'and', 'or', 'in']\nNUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n\nclass NumberFilter(whoosh.analysis.Filter):\n    def __call__(self, tokens):\n        for t in tokens:\n            if not NUMBER_REGEX.match(t.text):\n                yield t\n\ncustom_analyzer = whoosh.analysis.StandardAnalyzer(stoplist=BRS_STOPWORDS) | NumberFilter()","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:13:07.153859Z","iopub.execute_input":"2024-06-22T20:13:07.154287Z","iopub.status.idle":"2024-06-22T20:13:07.164953Z","shell.execute_reply.started":"2024-06-22T20:13:07.154248Z","shell.execute_reply":"2024-06-22T20:13:07.163802Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"query_validator = whoosh_utils.QueryValidator()\n\ndef validate_query(query):\n    query = \"ti:device\" if not len(query) or not isinstance(query, str) else query\n    try:\n        query_validator.validate_query(query)\n    except:\n        query = \"ti:device\"\n    return query","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:13:07.166118Z","iopub.execute_input":"2024-06-22T20:13:07.166463Z","iopub.status.idle":"2024-06-22T20:13:07.175349Z","shell.execute_reply.started":"2024-06-22T20:13:07.166434Z","shell.execute_reply":"2024-06-22T20:13:07.174406Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%%time\n\nkeywords_all = []\n\n#for i, row in tqdm(test_df[:30].iterrows(), total=test_df[:30].shape[0]):\nfor _, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n    # Keywords for one patent\n    keywords = []\n    \n    for j in range(CFG.num_neighbors):\n        keywords += generate_keyword(row, neighbor_idx=j)\n        \n    #tokens = [token.text for token in custom_analyzer(' '.join(keywords))]\n    #counter_object = Counter(tokens)\n\n    keywords1 = []\n    for keyword in keywords:\n        keywords1.append('(' + ' AND '.join([token.text for token in custom_analyzer(keyword)][:2]) + ')')\n    #print(keywords1)\n    counter_object = Counter(keywords1)\n    keywords = [x[0] for x in counter_object.most_common()]\n    \n    keywords_all.append(keywords)","metadata":{"execution":{"iopub.status.busy":"2024-06-22T20:13:07.176883Z","iopub.execute_input":"2024-06-22T20:13:07.177286Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/2846 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719087215.171296      34 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1719087215.256472      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1719087215.853150      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n 88%|████████▊ | 2493/2846 [3:19:45<27:16,  4.64s/it]  ","output_type":"stream"}]},{"cell_type":"code","source":"'''\n%%time\ntrain_idx = whoosh_utils.load_index('/kaggle/input/uspto-explainable-ai/train_index')\nsearcher = whoosh_utils.get_searcher(train_idx)\nqp = whoosh_utils.get_query_parser()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n#by words\nqueries = []\ns=0\ni=0\n\nfor _, row in test_df.iterrows():\n#for i, row in test_df[:30].iterrows():\n\n    '''p_cpc_codes = list(row[\"cpc_codes\"])\n\n    for j in range(CFG.num_neighbors):\n        p_cpc_codes.extend(row[f\"cpc_codes__{j}\"])\n    \n    counter_object = Counter(p_cpc_codes)\n    cpc = [x[0] for x in counter_object.most_common()]'''\n\n    cpc = row[\"main_cpc\"]\n\n    query_cpc = f\"cpc:({' OR '.join(cpc[:17])})\" if len(cpc) else \"\"\n    \n    try:\n        \n        keywords = keywords_all[i]\n        #keywords = '(' + ' ADJ2 '.join() + ')'\n        #print('keywords', keywords)\n\n        # number of query tokens must be <= 50\n        while len(keywords)>0:\n            ti_keywords = f\"({' OR '.join(keywords)})\"\n            #detd_keywords = f\"({' OR '.join(keywords)})\"\n            \n            #query = (f\"ti:{ti_keywords} OR (detd:{detd_keywords} AND \" + \n            #         (f\"{query_cpc}\" if len(query_cpc) else '') + \")\"\n            #        )\n            query = (f\"ti:{ti_keywords} AND \" +\n                     #f\"detd:{detd_keywords} AND \" +\n                     f\"{query_cpc}\")\n            #print('counts_tokens', whoosh_utils.count_query_tokens(query))\n            \n            if whoosh_utils.count_query_tokens(query) >50:\n                #print(whoosh_utils.count_query_tokens(query))\n                keywords = keywords[:-1]\n            else:\n                break\n\n    except:\n        query = query_cpc\n  \n    #query = query_cpc\n    \n    # Final query validation\n    query = validate_query(query)\n    \n    '''p_list = whoosh_utils.execute_query(query, qp, searcher)\n    n = 0\n    for p_num in p_list:\n        if p_num in list(row[1:51]): #.values.reshape(51)[1:]:\n            n += 1\n    s += n\n    print(i, f\"{n}/{row['nn']}. Total {s}\") #, len(p_list), '\\n', qp.parse(query))'''\n    \n    queries.append(query)\n    i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nprint(i, f\"{n}/{row['nn']}. Total {s}\", len(p_list), query)\nprint(qp.parse(query))\n'''\n#print('\\n'.join(queries))","metadata":{"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"91 1/6. Total 0 50 cpc:(H04L63/083 OR H04W12/06 OR G06F21/31 OR H04L63/083 OR G06F21/31 OR H04L63/08 OR G06F21/88 OR G07C2009/00769 OR H04W12/126 OR G06F21/36 OR G06F21/335 OR G06F21/35 OR G06F21/34 OR G06F21/305 OR G06F3/1204)\n(cpc:H04L63/083 OR cpc:H04W12/06 OR cpc:G06F21/31 OR cpc:H04L63/08 OR cpc:G06F21/88 OR cpc:G07C2009/00769 OR cpc:H04W12/126 OR cpc:G06F21/36 OR cpc:G06F21/335 OR cpc:G06F21/35 OR cpc:G06F21/34 OR cpc:G06F21/305 OR cpc:G06F3/1204)\n","output_type":"stream"}]},{"cell_type":"code","source":"'''0 5/7. Total 5 50 cpc:(F17C2221/033 OR F17C2223/0123 OR F17C2225/0123 OR F17C2225/036 OR F17C5/007 OR F17C2201/0109 OR F17C2201/032 OR F17C5/06 OR F17C2201/054 OR F17C2223/033 OR F17C2227/0192 OR F17C2250/01 OR F17C2265/065 OR F17C2270/0139 OR F17C2270/0171)\n1 2/6. Total 7 50 cpc:(G06F3/0488 OR G06F3/017 OR G06F21/32 OR H04M1/72403 OR H04M1/72522 OR H04N23/632 OR H04N5/23293 OR G02B2027/0187 OR G02B27/0093 OR G06F21/00 OR G06F3/012 OR G06F3/013 OR G06F3/0484 OR G06F3/14 OR H04M1/72409)\n2 1/6. Total 8 50 cpc:(G16H40/63 OR G16H40/67 OR G16H50/20 OR A61B5/1117 OR E04F15/105 OR E04F15/107 OR E04F19/0436 OR E04F19/061 OR E04F2019/044 OR E04F2290/02 OR G06N20/00 OR G06V20/52 OR G16H40/20 OR G16H50/70 OR G16H50/80)\n3 4/6. Total 12 50 cpc:(F02N15/067 OR F02N11/00 OR F02N15/022 OR F02N15/046 OR F02N15/062 OR Y10T74/132 OR F02N2015/061 OR F16D27/118 OR F02N15/023 OR F02N11/0814 OR F02N11/0851 OR F02N15/02 OR F02N15/04 OR F16D41/185 OR F02N15/065)\n4 1/7. Total 13 50 cpc:(G06K9/2018 OR G06K9/2027 OR G06V10/143 OR G06T7/90 OR H04N23/11 OR H04N5/332 OR G06T2207/10048 OR G06T2207/10152 OR G06T7/11 OR G06V10/141 OR G06V40/168 OR G06K9/00355 OR G06V40/28 OR H04N23/56 OR H04N5/2226)\n5 3/6. Total 16 50 cpc:(G05B15/02 OR Y02P90/82 OR G05F1/66 OR G06Q50/06 OR G06Q10/06 OR G01R21/133 OR Y02B90/20 OR Y02P90/84 OR Y02P90/845 OR H02J2203/20 OR H02J3/00 OR Y02B70/3225 OR Y02E60/00 OR Y04S20/222 OR Y04S40/20)\n6 0/6. Total 16 50 cpc:(C07C69/92 OR C07C201/16 OR C07C47/56 OR C07C47/565 OR C07C47/575 OR C07C51/29 OR C07C51/363 OR C07C51/367 OR C07C51/377 OR C07C65/05 OR C07C65/21 OR C07C67/035 OR C07C67/307 OR C07C67/317 OR C07C69/84)\n7 2/6. Total 18 50 cpc:(B25J19/0008 OR B25J19/0012 OR Y10S901/15 OR Y10S901/27 OR Y10T74/20305 OR B25J17/0216 OR B25J19/0091 OR B25J9/0057 OR B25J9/0075 OR B25J9/06 OR B25J9/08 OR B25J9/144 OR Y10S901/22 OR Y10S901/28 OR B66C13/20)\n8 1/6. Total 19 50 cpc:(G02B2027/014 OR G06T19/006 OR G02B2027/0138 OR G02B2027/0178 OR G02B27/017 OR G06F3/012 OR G02B27/0172 OR G02B27/0093 OR G06F3/013 OR G06T2207/30244 OR H04N23/90 OR H04N5/247 OR H04N13/344 OR G02B2027/0187 OR G06F3/011)\n9 2/6. Total 21 50 cpc:(G01N13/00 OR G01N1/2035 OR G01N33/2847 OR G01N11/04 OR G01N2021/8405 OR G01N21/85 OR G01N33/2823 OR G06F18/241 OR G06F18/256 OR G06K9/00134 OR G06K9/00147 OR G06K9/6268 OR G06K9/6293 OR G06V20/693 OR G06V20/698)\n10 3/6. Total 24 50 cpc:(G06N3/044 OR G06N3/045 OR G06N3/0445 OR G06N3/08 OR G06N3/0454 OR G06N3/084 OR G06N3/048 OR G06F16/345 OR G06F16/93 OR G06F40/30 OR G06F40/56 OR G06F40/216 OR G06F40/279 OR G06F40/40 OR G06N3/006)\n    \n90 3/6. Total 296 50 cpc:(H04W12/06 OR H04L63/083 OR G06F21/31 OR G06F21/316 OR H04M1/724631 OR H04W12/068 OR H04W12/08 OR H04W88/02 OR H04W12/30 OR H04W12/64 OR H04M1/72577 OR H04W12/126 OR G06F21/30 OR G06F21/41 OR G06F2221/2113)    '''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df[1:2]\n#test_df.nn.sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"query\"] = queries\nsubm = test_df[[\"publication_number\", \"query\"]]\nsubm.to_csv(\"submission.csv\", index=False)\nsubm.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T12:52:28.045551Z","iopub.execute_input":"2024-06-21T12:52:28.046024Z","iopub.status.idle":"2024-06-21T12:52:28.067130Z","shell.execute_reply.started":"2024-06-21T12:52:28.045992Z","shell.execute_reply":"2024-06-21T12:52:28.065805Z"},"trusted":true},"execution_count":null,"outputs":[]}]}